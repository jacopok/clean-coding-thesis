---
# compile with:
# pandoc -f markdown-implicit_figures --citeproc galileian_thesis.md --toc -o galileian_thesis.pdf

title: "Best practices in scientific coding: a case study"
author: Jacopo Tissino
date: October 2022
geometry: "left=3.5cm,right=3.5cm,top=2.5cm,bottom=2.5cm"
output: pdf_document
colorlinks: true
linkcolor: blue
link-citations: true
bibliography: [Galithesis.bib]
abstract: |
  Scientific software is often experimental and thus messy, 
  undocumented, not reusable. As a given piece of software grows 
  in user count, though, it can benefit in applying 
  development best practices which are well-known in the 
  industry setting.  
  This thesis will discuss a selection of these practices and show
  their application for a `python` project named
  `GWFish`, a Fisher matrix code used for gravitational wave
  data analysis.
header-includes: |
  \usepackage{siunitx}



hyperrefoptions:
- linktoc=all
- linkcolor=blue

---

# Introduction

Scientists notoriously write bad code.
This is a thorny statement, and it should be qualified: code may be "bad" 
according to the standards of companies, but if its purpose is the investigation 

Using `GWFish` [@harmsGWFishSimulationSoftware2022] to demostrate 
these software practices is something of a perfect storm. 
It is a very young piece of software (its development started in early 2021)
which serves a conceptually simple purpose, and which 
can be useful to a large amount of people.

## GWFish in short

What follows is a short explanation of what this piece of software does, 
aimed at non-physicists. I will first introduce the concept of gravitational 
wave detection and the purpose of `GWFish` at a general level, without
the mathematical details.
Then, I will go into more detail into the things it needs to compute,
including some math, but still at a level which an undergraduate
in a scientific field should be able to understand.

The first direct measurement of gravitational waves was accomplished 
in 2015 by the LIGO interferometers in the United States.

In 2017 they were joined by the Virgo interferometer in Italy, and
the network has since detected almost 100 distinct signals. 
Most of these signals were generated by pairs of black holes orbiting each other,
with the remaining few corresponding to pairs of neutron stars or one neutron star 
and one black hole.

By lowering the noise in the interferometer, we went from no detection 
to about one signal per week. This has already been called the birth of a 
new era of _gravitational wave astronomy_, which can complement "regular" 
electromagnetic astronomy. 

A lot of interest is going towards the question: how can we do better?
Which kinds of new detectors are best if we want to detect even more 
gravitational waves?
These instruments are big, expensive projects, therefore a careful scientific
evaluation of what we think a new detector concept might be able to 
accomplish is crucial when outlining a funding proposal.

<!-- We have experimental evidence that, at least at a basic level, our understanding
of how gravitational waves are generated and propagate through space 
is correct; therefore, the typical procedure is to extrapolate this knowledge 
in order to evaluate  -->

The basic questions we wish to answer for any new detector concept are:

- which kinds gravitational wave sources will it be able to detect? how many of them?
- how well will it be able to estimate the properties of these sources?

answer to these questions for a wide range of future detector proposals.
The answers necessarily depend on two aspects: 

- given a specific astrophysical source, can _detector X_ measure it? 
  If so, how well?
  - for example, consider a pair of black holes, with masses so-and-so, 
    at a distance of such-and-such...
- how many of that astrophysical source kind are there? how far away are they?
  - for example, what is the distribution of black hole binaries? what are their
    typical masses, how often do they occur in any given universe volume?


`GWFish` is a piece of software built for the purpose of giving an approximate
answer to the _first_ of these questions. The second is much harder to deal with
even for the sources we have direct knowledge of (black holes, neutron stars, white 
dwarfs), bordering on impossible for more exotic and hypothetical sources 

- Matched filtering
- Meaning of SNR
- Fisher matrix error estimation
- 

### Matched filtering

This is a basic technique used for all modern gravitational data analysis.
The idea is that we want to extract a very weak signal which is submerged in noise.
A complete overview of the method can be found in [@maggioreGravitationalWavesVolume2007],
here I will give a very brief one.

The raw strain data from a GW detector looks like this:

![Raw data](figures/bare.pdf)

It is clear that the largest contribution in terms of amplitude is an oscillation
with period on the order of a couple of seconds, and amplitude on the order of a few times $10^{-18}$
(dimensionless strain).

The signal we want to measure is at least three orders of magnitude smaller! What can we do?
The first step is to look at the "Fourier spectrum" of these data (more specifically, the 
amplitude spectral density, but thinking of it as the amplitude of the Fourier transform is not 
terrible):

![Amplitude spectral density](figures/asd.pdf)

We are not even showing the part of the spectrum with period on the order a few seconds,
the trend at low frequency continues and the amplitude for $f \sim \qty{1}{Hz}$ there is enormous. 
This detector is _not sensitive_ to signals with very low frequency, but it _is_ sensitive to 
signals with frequencies in a band around 100Hz. 

The first step towards actually measuring something lies in 
_whitening_ the measured data, that is, dividing every Fourier component by its root-mean-square value. 
After this procedure, our data looks like this:

![Whitened strain](figures/whitened.pdf)

and still, no signal is visible!
This is because the signal present in these data has high frequency and low amplitude; specifically, if we were to plot it 
together with these data, it would look like this: 

![Whitened strain and signal](figures/true_signal.pdf)

So, how can we possibly detect something that is so far smaller in amplitude than our data?

The trick lies in a technique called _matched filtering_. in which 
we use the fact that, if our measured data is $d(t) = n(t) + s(t)$, 
with $n(t)$ being the noise and $s(t)$ being the astrophysial signal (suppose here 
that it is monochromatic for simplicity), then a temporal integral in the form 

$$ I
= \frac{1}{T} \int d(t) s(t) \mathrm{d}t 
= \underbrace{\frac{1}{T} \int n(t) s(t) \mathrm{d}t}_{I_n} +
\underbrace{\frac{1}{T} \int s(t) s(t) \mathrm{d}t}_{I_s}\,,
$$

where $T$ is the length of the integration period, has two components: 
$I_s$ is the average square magnitude of the signal, and it approaches a constant;
on the other hand, $I_n$ varies stochastically with $n$, but since $n$ and $s$ have 
no reason to be correlated the integral will be a random process with variance $T$, 
and due to the division by $T$ this term will decay like $I_n \sim T^{-1/2}$.

This is the essence of gravitational data analysis: if we know the expected signal ahead of time,
we may extract its contribution from noisy data. 
The integrals above are optimal if the case of white noise, but going back to the actually-measured
data the procedure is slightly more complicated. 

Now, jumping ahead to the final result: 
we need to estimate the noise power spectral density (noise power per frequency bin) $S_n(f)$,
and use to define with it the scalar product between timeseries $d(t)$ and $h(t)$ in terms 
of their Fourier transforms $\widetilde{d}(f)$ and $\widetilde{h}(f)$ as follows:

$$ (d | h) = 4 \Re \int _0^{ \infty } \frac{\widetilde{d}(f) \widetilde{h}(f)}{S_n(f)}\mathrm{d}f
$$

This product is the basis for signal searches, which are performed by
looking for peaks in the following function of $t$:

$$ (\text{observed strain data }d | h \text{ shifted by a time }t)
$$

for a selection ("template bank") of plausible signals $h$ we might see.

Similarly, parameter estimation for any observed signal $d$ is performed by 
exploring the posterior defined by the likelihood 

$$ 
\mathcal{L} (d | \theta ) 
= \mathcal{N} \exp \left(- \frac{1}{2} (d - h(\theta )| d - h(\theta ))\right)
$$

where $\mathcal{N}$ is an irrelevant normalization. 

### Fisher matrix error estimation

Up to now we discussed the analysis of current data; the question `GWFish` seeks to answer, 
on the other hand, pertains to data taken by detectors we have not built yet.
We can, however, make estimates as to what their noise level will be and go from there. 

So, suppose we ask: 

> Given the estimated noise curve of the planned Einstein Telescope gravitational wave interferometer,
> suppose that two black holes with masses $M_1 = M_2 = 30 M_{\odot}$ (solar masses)
> merge at a distance of $10^9$ light years from Earth.^[The problem as stated is under-specified,
> there are several other parameters to consider, but let us keep it simple here.] 
> How well could we measure their masses, distance, and position from the gravitational wave data?

The "proper" way to answer this question would be to simulate noise distributed according
to the given noise curve, add the known signal to it, and analyze it as if it were real data.
This can be done, and it _is_ done to a certain extent, but it is very expensive: a single analysis of this kind takes
several hours to days (for current detectors as well, but there we know it to be worth it since it's actual
astrophysical data).

This prevents us from exploring things such as the dependence of the results on things 
such as the masses of the black holes, the distance and so on, as that requires re-doing 
the aforementioned analysis several times.
The solution (or at least a partial one) is to make an approximation, 
called the _Fisher matrix approximation_: basically, we take the aforementioned likelihood, 
and approximate it as a multivariate Gaussian in the parameters $\theta$, with mean given by the values we selected.
Then, we may compute its covariance matrix by looking at the (negative expectation value of the) 
Hessian of $\log \mathcal{L}$ computed at that maximum-likelihood point, which is called the Fisher matrix:

$$ \mathcal{F}_{ij} = - \mathbb{E} \left( 
  \frac{\partial}{\partial \theta _i} 
  \frac{\partial}{\partial \theta _j}  
  \log \mathcal{L} (d | \theta )
\right)
=  \mathbb{E}
\frac{\partial}{\partial \theta _i} 
\frac{\partial}{\partial \theta _j}  
\left( \frac{1}{2} (d - h(\theta )| d - h(\theta )) \right)
$$

Taking the expectation value amounts to looking at the case in which the noise equals zero, 
i.e. $d-h(\theta) = 0$; going through the derivatives we find that the only non-vanishing contribution is
$\mathcal{F}_{ij} = (\partial_i h | \partial_j h)$, again evaluated at the maximum likelihood point.

This is the basic quantity `GWFish` is computing; we are approximating the likelihood as a 
Gaussian in the form $\log \mathcal{L} \sim - \theta_i \mathcal{F}_{ij} \theta _j / 2$ (with the 
[Einstein summation convention](https://en.wikipedia.org/wiki/Einstein_notation)). 
We may then use the properties of multivariate Gaussians, and state that our estimate for 
the variance of parameter $i$ is given in terms of the diagonal components of the inverse of $\mathcal{F}$:

$$ \sigma^2 _i \approx (\mathcal{F}^{-1})_{ii}\,.
$$

# Documentation

A crucial aspect in software usability is the presence of good documentation.
In my experience, when this is brought up people's mind often goes to "comments
in the code"; but these are not proper _documentation_. 
Documentation is meant for the _user_ of our code, while line comments 
are at best useful for future developers.

[@martinCleanCodeHandbook2008]

## The diátaxis framework

The diátaxis framework [@procidaDiataxisDocumentationFramework2022] 
allows us to structure our thinking about documentation
according to the needs of the user, as opposed to our convenience
when writing the code.

Although it is not software documentation exactly, let me state that 
this document here is written to be mostly in the _tutorial_ category,
giving examples with concrete steps meant for study, which will not 
be directly applicable to users' code.
An exception for this is the introductory section, which falls 
in the _explanation_ category.

## Documentation for GWFish

# Testing

## Unit testing for matrix inversion

This section showcases how unit tests can be added to a relatively 
simple section of code.
We start by outlining what this section of code is doing.

### Fisher matrix inversion and singularity issues

Within `GWFish`, an important step is the inversion of the Fisher matrix, which is 
required in order to provide estimates of the errors on the parameters.

This by itself does not seem like a difficult task computationally: 
after all, the matrices at hand are not very large (on the order of $10\times 10$). 
However, issues do arise due to the differences in the magnitude 
between the various components.

Because of them, the code which does the inversion within `GWFish` looks like this:

```python
import numpy as np

def invertSVD(matrix):
    thresh = 1e-10

    dm = np.sqrt(np.diag(matrix))
    normalizer = np.outer(dm, dm)
    matrix_norm = matrix / normalizer

    [U, S, Vh] = np.linalg.svd(matrix_norm)

    kVal = sum(S > thresh)
    matrix_inverse_norm = U[:, 0:kVal] @ np.diag(1. / S[0:kVal]) @ Vh[0:kVal, :]

    return matrix_inverse_norm / normalizer
```

Let us leave the mathematical details aside and think like computer scientists.
This code should invert a matrix: does it do that?

### The simplest test

Let us start by building the simplest kind of test possible, which will already allow
us to showcase some ideas about automated testing.

We can start by adding a testing function to the same script as the one in which the 
`invertSVD` function is defined. 
The basic paradigm in testing is, of course, to run the code with some input 
and see whether it produces the correct result.
We will eventually need these test inputs to include high-dimensional, 
singular or nearly singular matrices, but let us start small. 
We will use a symmetric matrix, since all Fisher matrices are symmetric,
and since the algorithm used for the normalization breaks down otherwise.

```python
def test_matrix_inversion():

    matrix = np.array([[1, 3], [3, 4]])
    inverse = invertSVD(matrix)

    inverse_should_be = np.array([[-4/5, 3/5], [3/5, -1/5]])
    return np.allclose(inverse, inverse_should_be)

if __name__ == '__main__':
    print(test_matrix_inversion())
```

As expected, when running the script we get the result `True`;
on the other hand, if we change one of the numbers in the `inverse_should_be` 
matrix we get `False`.

Several problems with this appear right away: do we really need to manually 
compute matrix inverses to test our code?
We will get to that; first, though, let us _refactor_ our test.

As is, we need to actively look at the output of the script in order to 
see whether our test has succeeded or failed.
Also, the test and the actual code live in the same file, which is not 
great: as we add more tests, it will become a source of clutter.

### Using `pytest`

Our first refactoring step lies in moving the test code to its own script.
Also, as opposed to returning a boolean value, we will use an `assert` statement,
as is common when using `pytest`. 

`assert` is a convenient tool for debugging and testing: 
a statement like `assert x` will not do anything if `x` is truthy, 
while it will fail with an `AssertionError` if `x` is falsey.

So, our code will look like:

```python
from gwfish_matrix_inverse import invertSVD
import numpy as np

def test_matrix_inversion():

    matrix = np.array([[1, 3], [3, 4]])
    inverse = invertSVD(matrix)

    inverse_should_be = np.array([[-4/5, 3/5], [3/5, -1/5]])
    assert np.allclose(inverse, inverse_should_be)

if __name__ == '__main__':
    test_matrix_inversion()
```

and, unlike before, it will now not output anything if everything is working
correctly, and raise an error if not (try it!).

The next step is to try the same thing with the `pytest` library.
We first need to install it (`pip install pytest`); after that, in 
the folder containing these files, we may simply run:

```bash
$ pytest
============================= test session starts ==============================
platform linux -- Python 3.9.11, pytest-7.1.3, pluggy-1.0.0
rootdir: /home/jacopo/Documents/clean-coding-thesis/scripts/testing_2
collected 1 item                                                               

test_matrix_inverse.py .                                                 [100%]

============================== 1 passed in 0.07s ===============================
```

`pytest` is able to go through the files in the folder, see that 
one of them has a name starting with `test_`, inside it 
there's a function starting with `test_`, run that function, find no 
errors, give us a success!

Note that now calling the function `test_matrix_inversion` in the script is not
required anymore: we may safely remove those last two lines.

What happens if the test fails? Here, `pytest` really shines: 
let us change one of the numbers in the should-be inverse, and re-run the same 
command:

```python
$ pytest
============================= test session starts ==============================
platform linux -- Python 3.9.11, pytest-7.1.3, pluggy-1.0.0
rootdir: /home/jacopo/Documents/clean-coding-thesis/scripts/testing_2
collected 1 item                                                               

test_matrix_inverse.py F                                                 [100%]

=================================== FAILURES ===================================
____________________________ test_matrix_inversion _____________________________

    def test_matrix_inversion():
    
        matrix = np.array([[1, 3], [3, 4]])
        inverse = invertSVD(matrix)
    
        inverse_should_be = np.array([[-4/5, 3/6], [3/5, -1/5]])
>       assert np.allclose(inverse, inverse_should_be)
E       assert False
E        +  where False = <function allclose at 0x7f25d5d27280>(array([[-0.8,  0.6],
       [ 0.6, -0.2]]), array([[-0.8,  0.5],\n       [ 0.6, -0.2]]))
E        +    where <function allclose at 0x7f25d5d27280> = np.allclose

test_matrix_inverse.py:10: AssertionError
=========================== short test summary info ============================
FAILED test_matrix_inverse.py::test_matrix_inversion - assert False
============================== 1 failed in 0.12s ===============================
```

`pytest` ran our test code and found an error.
It tells us exactly where it found it, and specifically how it came about:
we used the `np.allclose` function to check for the equality of two matrices 
which it prints out, so we can see at a glance what has gone wrong. 

Of course, we might not understand where the problem is right away in general,
but this all is about convenience, and having the tools at hand to spot 
as many details as possible.

#### Debugging

Often, the information shown by `pytest` will still not be enough. 
A really convenient thing to be able to do, then, is to start from the 
failure and work interactively with the variables defined at that time:
this way, we can do all sorts of manipulations, or even make plots if we 
want!

This is easily achieved by adding the `--pdb` flag to our call to `pytest`.
`pdb`, "python debugger", is a standard tool for debugging, and it has
plenty of features worth exploring. Here I will give just a flavor of the 
possibilities. 

The shell looks like this:

```python
$ pytest --pdb
[... same output as before ...]
test_matrix_inverse.py:10: AssertionError
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> entering PDB >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

>>>>>>>>>>>>>>>>>> PDB post_mortem (IO-capturing turned off) >>>>>>>>>>>>>>>>>>>
> /home/jacopo/Documents/clean-coding-thesis/scripts/testing_2/
  test_matrix_inverse.py(10)test_matrix_inversion()
-> assert np.allclose(inverse, inverse_should_be)
(Pdb) matrix @ inverse
array([[ 1.00000000e+00, -1.11022302e-16],
       [ 4.44089210e-16,  1.00000000e+00]])
(Pdb) matrix @ inverse_should_be
array([[ 1.0000000e+00, -1.0000000e-01],
       [-4.4408921e-16,  7.0000000e-01]])
(Pdb) q


=========================== short test summary info ============================
FAILED test_matrix_inverse.py::test_matrix_inversion - assert False
!!!!!!!!!!!!!!!!!!! _pytest.outcomes.Exit: Quitting debugger !!!!!!!!!!!!!!!!!!!
```

It is hard to show in a fixed medium such as this, but I was presented with 
a shell prompt `(Pdb)`, from which I could give arbitrary `python` commands.

I used it to compute the matrix product between the initial matrix
and the computed inverse, and the same between the manually-written inverse,
which showed that the computed inverse was indeed correct.


# Code structure

## 